{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Classifying Wine Quality Data Based on Different Supervised Learning Methods\n",
    "#Data Adjustment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Specifying the file path\n",
    "file_path = r'E:\\Study Materials\\Masters Data Science\\1-1\\Introduction to Python\\Assisgnment\\wine-quality white.csv'\n",
    "\n",
    "# Loading the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.head())\n",
    "\n",
    "# according to the instruction of the assignment append new rows.\n",
    "# my id=05, Thus X=0.05 and it will be added to the values of the new rows.\n",
    "X = 0.05\n",
    "r1 = np.round([7.8 + X, 0.88 + X, 0 + X, 1.9, 0.09 + X, 25 + X, 67 + X, .991 + X, 3.22, 0.68 + X, 9.8 + X, 5], 2)\n",
    "r2 = np.round([7.2 + X, 0.83 + X, 0.01 + X, 2.2, 0.19 + X, 15 + X, 60 + X, .996 + X, 3.52, 0.55 + X, 9.6 + X, 6], 2)\n",
    "r3 = np.round([7.9 + X, 0.89 + X, 0.01 + X, 1.7, 0.08 + X, 22 + X, 57 + X, .997 + X, 3.26, 0.64 + X, 9.8 + X, 2], 2)\n",
    "r4 = np.round([7.7 + X, 0.86 + X, 0.02 + X, 2.3, 0.07 + X, 11 + X, 38 + X, .994 + X, 3.12, 0.08 + X, 9.4 + X, 3], 2)\n",
    "dataSeries = [pd.Series(r1, index=df.columns), pd.Series(r2, index=df.columns),\n",
    "              pd.Series(r3, index=df.columns), pd.Series(r4, index=df.columns)]\n",
    "\n",
    "df2 = pd.concat([df, pd.DataFrame(dataSeries)], ignore_index=True)\n",
    "print(df2)\n",
    "\n",
    "#### Modifying quality column as per assignment\n",
    "#### reallocating the quality of wine as 1: 0 to 5 (Bad quality) and 2: 6 to 10 (Good quality).\n",
    "df2[[df2[['quality']] <= 5.0]]=1\n",
    "df2[[df2[['quality']] > 5.0]]=2\n",
    "df2['quality'] = df2['quality'].map({1:'Bad', 2:'Good'})\n",
    "print (df2)\n",
    "\n",
    "##Logistic Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Defining feature variables (X) and target variable (y)\n",
    "X = df2.drop('quality', axis=1)\n",
    "y = df2['quality']\n",
    "\n",
    "# Convert 'Good' and 'Bad' to numerical labels (0 and 1)\n",
    "y = y.apply(lambda label: 1 if label == 'Good' else 0)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# ROC Curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label=1)  # Specify pos_label\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate and interpret performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision (Positive Predictive Value):\", precision)\n",
    "print(\"Recall (Sensitivity):\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "##Decision Tree Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Defining feature variables (X) and target variable (y)\n",
    "X = df2.drop('quality', axis=1)\n",
    "y = df2['quality']\n",
    "\n",
    "# Convert 'Good' and 'Bad' to numerical labels (0 and 1)\n",
    "y = y.apply(lambda label: 1 if label == 'Good' else 0)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Decision Tree model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# ROC Curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label=1)  # Specify pos_label\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate and interpret performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision (Positive Predictive Value):\", precision)\n",
    "print(\"Recall (Sensitivity):\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "##Random Forest Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Defining feature variables (X) and target variable (y)\n",
    "X = df2.drop('quality', axis=1)\n",
    "y = df2['quality']\n",
    "\n",
    "# Convert 'Good' and 'Bad' to numerical labels (0 and 1)\n",
    "y = y.apply(lambda label: 1 if label == 'Good' else 0)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Random Forest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# ROC Curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label=1)  # Specify pos_label\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate and interpret performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision (Positive Predictive Value):\", precision)\n",
    "print(\"Recall (Sensitivity):\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "##Support Vector Machine Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Defining feature variables (X) and target variable (y)\n",
    "X = df2.drop('quality', axis=1)\n",
    "y = df2['quality']\n",
    "\n",
    "# Convert 'Good' and 'Bad' to numerical labels (0 and 1)\n",
    "y = y.apply(lambda label: 1 if label == 'Good' else 0)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Support Vector Machines model\n",
    "model = SVC(probability=True)  # Enable probability estimation for ROC curve\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# ROC Curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label=1)  # Specify pos_label\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate and interpret performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision (Positive Predictive Value):\", precision)\n",
    "print(\"Recall (Sensitivity):\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
